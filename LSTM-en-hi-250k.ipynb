{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c57fba",
   "metadata": {},
   "source": [
    "### This notebook trains and evaluates an LSTM model for 250000 sentences for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208baf52-4640-4440-8991-8d8168aa0689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, TerminateOnNaN\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the Util file\n",
    "import util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ff6a2",
   "metadata": {},
   "source": [
    "### This loads and preprocesses the data - making sure that only the unique sentences are stored to avoid any repitition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130892ef-33bd-4628-81c9-d3509b5d7b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"cfilt/iitb-english-hindi\")\n",
    "data = raw_datasets[\"train\"][\"translation\"]\n",
    "    \n",
    "eng_sen = []\n",
    "hin_sen = []\n",
    "\n",
    "for item in data:\n",
    "  eng_sen.append(item['en'])\n",
    "  hin_sen.append(item['hi'])\n",
    "    \n",
    "eng_sen = [util.preprocess(en) for en in eng_sen]\n",
    "hin_sen = [re.sub('[a-zA-Z]', '', util.preprocess(hi)) for hi in hin_sen]\n",
    "\n",
    "# Remove duplicate sentences\n",
    "eng_sen, hin_sen = util.unique_sentences(eng_sen, hin_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "321130e2-acb4-4a14-888a-04d9b212fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sentences = 250000\n",
    "max_len = 10\n",
    "epochs = 20\n",
    "val_split = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f114e8e-1003-44cb-8774-2b618fce0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = []\n",
    "hi_data = []\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for (en, hi) in zip(eng_sen, hin_sen):\n",
    "  l = min(len(en.split()), len(hi.split()))\n",
    "  if l <= max_len:\n",
    "    en_data.append(en)\n",
    "    hi_data.append(hi)\n",
    "    cnt += 1\n",
    "  if cnt == total_sentences:\n",
    "    break\n",
    "\n",
    "hi_data = ['<START> ' + hi + ' <END>' for hi in hi_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e05f8",
   "metadata": {},
   "source": [
    "### This creates the tokenizer for both languages using Keras Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f967aa-aa1d-46bc-b574-a64797b4a793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab Size: 78052\n",
      "Hindi Vocab Size: 81041\n"
     ]
    }
   ],
   "source": [
    "en_tokenizer = Tokenizer(filters='', oov_token='', lower=False)\n",
    "en_tokenizer.fit_on_texts(en_data)\n",
    "en_sequences = en_tokenizer.texts_to_sequences(en_data)\n",
    "\n",
    "hi_tokenizer = Tokenizer(filters='', oov_token='', lower=False)\n",
    "hi_tokenizer.fit_on_texts(hi_data)\n",
    "hi_sequences = hi_tokenizer.texts_to_sequences(hi_data)\n",
    "\n",
    "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
    "hi_vocab_size = len(hi_tokenizer.word_index) + 1\n",
    "print(\"English Vocab Size:\", en_vocab_size)\n",
    "print(\"Hindi Vocab Size:\", hi_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123bd98",
   "metadata": {},
   "source": [
    "### This sets up the data for the encoders and decoders using Keras pad_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98534ff2-6b98-4c25-a06e-fbd453143fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Encoder\n",
    "encoder_inputs = pad_sequences(en_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Prepare Decoder\n",
    "decoder_inputs = []\n",
    "decoder_outputs = []\n",
    "\n",
    "for hi in hi_sequences:\n",
    "    decoder_inputs.append(hi[:-1])\n",
    "    decoder_outputs.append(hi[1:])\n",
    "\n",
    "decoder_inputs = pad_sequences(decoder_inputs, maxlen=max_len, padding='post')\n",
    "decoder_outputs = pad_sequences(decoder_outputs, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c86077-e7a4-45c2-a52f-6ca66a73ba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237500, 10) (237500, 10) (237500, 10)\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing split: 95%, 5%\n",
    "split = int(0.95 * total_sentences)\n",
    "\n",
    "X_train = [encoder_inputs[:split], decoder_inputs[:split]]\n",
    "y_train = decoder_outputs[:split]\n",
    "\n",
    "# Test data to evaluate our NMT model using BLEU score\n",
    "X_test = en_data[:split]\n",
    "y_test = hi_data[:split]\n",
    "\n",
    "print(X_train[0].shape, X_train[1].shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f3dfe",
   "metadata": {},
   "source": [
    "### This creates the LSTM model of 256 units with the Encoders and Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31c54ae-5343-4201-b5f2-7365b631682a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 256)            1998131   ['input_1[0][0]']             \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 256)            2074649   ['input_2[0][0]']             \n",
      "                                                          6                                       \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, None, 256),          525312    ['embedding[0][0]']           \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 256),          525312    ['embedding_1[0][0]',         \n",
      "                              (None, 256),                           'lstm[0][1]',                \n",
      "                              (None, 256)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 81041)          2082753   ['lstm_1[0][0]']              \n",
      "                                                          7                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62605969 (238.82 MB)\n",
      "Trainable params: 62605969 (238.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM model\n",
    "num_units = 256\n",
    "\n",
    "# Encoder\n",
    "inputs = Input(shape=(None,))\n",
    "input_embed = Embedding(en_vocab_size, num_units, mask_zero=True)(inputs)\n",
    "lstm = LSTM(num_units, activation='relu', return_sequences=True, return_state=True)\n",
    "seq_output, memory_state, carry_state = lstm(input_embed)\n",
    "\n",
    "# Decoder\n",
    "targets = Input(shape=(None,))\n",
    "input_embed = Embedding(hi_vocab_size, num_units, mask_zero=True)(targets)\n",
    "decoder_lstm = LSTM(num_units, activation='relu', return_sequences=True, return_state=True)\n",
    "seq_output, memory_state, carry_state = decoder_lstm(input_embed, initial_state=[memory_state, carry_state])\n",
    "\n",
    "dense = Dense(hi_vocab_size, activation='softmax')\n",
    "input_embed = dense(seq_output)\n",
    "\n",
    "model = Model(inputs=[inputs, targets], outputs=input_embed)\n",
    "model.summary()\n",
    "\n",
    "loss = SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce34dfe4",
   "metadata": {},
   "source": [
    "### Fits the model and saves it after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad14cc9-d93d-4064-aaa8-1ef95add2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model after each epoch\n",
    "save_model_callback = ModelCheckpoint(\n",
    "    filepath='en-hi-50k',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, validation_split=val_split, callbacks=[save_model_callback, TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06e4d9",
   "metadata": {},
   "source": [
    "### Creates graphs for loss and accuracy (and for validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877e49a-1650-475c-8d9d-8d40eae17e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.history.history['loss']\n",
    "acc = model.history.history['accuracy']\n",
    "epoch_count = range(1, len(loss) + 1)\n",
    "\n",
    "# Visualize graph\n",
    "plt.plot(epoch_count, loss, 'r--')\n",
    "plt.plot(epoch_count, acc, 'b-')\n",
    "plt.legend(['Training Loss', 'Accuracy'])\n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylabel('Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aff80c-d5eb-4f4f-bd66-c4042b67a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = model.history.history['val_accuracy']\n",
    "val_loss = model.history.history['val_loss']\n",
    "\n",
    "# Visualize graph\n",
    "plt.plot(epoch_count, val_acc, 'g-')\n",
    "plt.plot(epoch_count, val_loss)\n",
    "plt.legend(['Validation Accuracy', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e45e2f",
   "metadata": {},
   "source": [
    "### Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6cc90f-b36e-435b-b889-7ce2cdd75860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 256)            1998131   ['input_1[0][0]']             \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 256)            2074649   ['input_2[0][0]']             \n",
      "                                                          6                                       \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 256),                525312    ['embedding[0][0]']           \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 256),          525312    ['embedding_1[0][0]',         \n",
      "                              (None, 256),                           'lstm[0][1]',                \n",
      "                              (None, 256)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 81041)          2082753   ['lstm_1[0][0]']              \n",
      "                                                          7                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62605969 (238.82 MB)\n",
      "Trainable params: 62605969 (238.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Retrieve previously saved stuff\n",
    "saved_model = load_model('en-hi-250k')\n",
    "\n",
    "saved_model.summary()\n",
    "inputs = saved_model.get_layer('input_1').output\n",
    "_, memory_state, carry_state = saved_model.get_layer('lstm').output\n",
    "targets = saved_model.get_layer('input_2').output\n",
    "embedding_layer = saved_model.get_layer('embedding_1')\n",
    "decoder_lstm = saved_model.get_layer('lstm_1')\n",
    "dense = saved_model.get_layer('dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367a990",
   "metadata": {},
   "source": [
    "### This sets up the inference model that will be used when predicting the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e0ec83b-c0f8-4976-a48a-fcd02c22ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Model\n",
    "num_units = 256\n",
    "max_len = 10\n",
    "\n",
    "# Encoder\n",
    "encoder = Model(inputs, [memory_state, carry_state])\n",
    "\n",
    "# Decoder\n",
    "decoder_input_memory = Input(shape=(num_units,))\n",
    "decoder_input_carry = Input(shape=(num_units,))\n",
    "input_embed = embedding_layer(targets)\n",
    "input_embed, decoder_output_memory, decoder_output_carry = decoder_lstm(input_embed, initial_state=[decoder_input_memory, decoder_input_carry])\n",
    "input_embed = dense(input_embed)\n",
    "decoder = Model([targets] + [decoder_input_memory, decoder_input_carry], \n",
    "                                [input_embed] + [decoder_output_memory, decoder_output_carry])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4078e1",
   "metadata": {},
   "source": [
    "### This method predicts the sentence from the model\n",
    "\n",
    "As it can be seen, the sentence starts and ends with `<START>` and `<END>` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edc77e66-02de-4162-9074-4b160e30131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(text):\n",
    "\tinput_seq = en_tokenizer.texts_to_sequences([text])\n",
    "\tnext_memory, next_carry = encoder.predict(input_seq)\n",
    "\n",
    "\tcurr_token = np.zeros((1, 1))\n",
    "\tcurr_token[0, 0] = hi_tokenizer.word_index['<START>']\n",
    "\n",
    "\tpred_sentence = ''\n",
    "\tnext_word = ''\n",
    "\ti = 0\n",
    "\twhile next_word != '<END>' and i <= max_len:\n",
    "\t\toutput, next_memory, next_carry = decoder.predict([curr_token] + [next_memory, next_carry])\n",
    "\t\tnext_token = np.argmax(output[0, 0, :])\n",
    "\t\tnext_word = hi_tokenizer.index_word[next_token]\n",
    "\t\tpred_sentence += ' ' + next_word\n",
    "\t\tcurr_token[0, 0] = next_token\n",
    "\t\ti += 1\n",
    "\n",
    "\treturn pred_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f543cdd-bb65-401a-a1c4-ba18ae37f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Input: give your application an accessibility workout\n",
      "Prediction: अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें\n",
      "Dataset Reference: अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें \n",
      "\n",
      "i = 1\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Input: accerciser accessibility explorer\n",
      "Prediction: एक्सेर्साइसर पहुंचनीयता अन्वेषक\n",
      "Dataset Reference: एक्सेर्साइसर पहुंचनीयता अन्वेषक \n",
      "\n",
      "i = 2\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Input: the default plugin layout for the bottom panel\n",
      "Prediction: निचले के लिए डिफोल्ट प्लगइन\n",
      "Dataset Reference: निचले पटल के लिए डिफोल्ट प्लगइन खाका \n",
      "\n",
      "i = 3\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Input: the default plugin layout for the top panel\n",
      "Prediction: ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका\n",
      "Dataset Reference: ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका \n",
      "\n",
      "i = 4\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Input: a list of plugins that are disabled by default\n",
      "Prediction: प्लगइन के प्रकार की सूची निष्क्रिय है\n",
      "Dataset Reference: उन प्लगइनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है \n",
      "\n",
      "i = 5\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Input: highlight duration\n",
      "Prediction: अवधि को हाइलाइट रकें\n",
      "Dataset Reference: अवधि को हाइलाइट रकें \n",
      "\n",
      "i = 6\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Input: the duration of the highlight box when selecting accessible nodes\n",
      "Prediction: बंद मोड हल्की प्रदर्शन चुनने के लिए क्लिक करें\n",
      "Dataset Reference: पहुंचनीय आसंधि नोड को चुनते समय हाइलाइट बक्से की अवधि \n",
      "\n",
      "i = 7\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Input: highlight border color\n",
      "Prediction: सीमांत बोर्डर के रंग को हाइलाइट करें\n",
      "Dataset Reference: सीमांत बोर्डर के रंग को हाइलाइट करें \n",
      "\n",
      "i = 8\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Input: the color and opacity of the highlight border\n",
      "Prediction: हाइलाइट किए गए सीमांत का रंग व अपारदर्शिता।\n",
      "Dataset Reference: हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। \n",
      "\n",
      "i = 9\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Input: highlight fill color\n",
      "Prediction: भराई के रंग को हाइलाइट करें\n",
      "Dataset Reference: भराई के रंग को हाइलाइट करें \n",
      "\n",
      "i = 10\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Input: the color and opacity of the highlight fill\n",
      "Prediction: हाइलाइट किया गया भराई का रंग और पारदर्शिता।\n",
      "Dataset Reference: हाइलाइट किया गया भराई का रंग और पारदर्शिता। \n",
      "\n",
      "i = 11\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Input: api browser\n",
      "Prediction: एपीआई विचरक\n",
      "Dataset Reference: एपीआई विचरक \n",
      "\n",
      "i = 12\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Input: browse the various methods of the current accessible\n",
      "Prediction: वर्तमान चयनित कार्य की एक सूची की जाँच करें\n",
      "Dataset Reference: इस समय जिसे प्राप्त किया गया हो उसकी विभिन्न विधियों मेथड में विचरण करें \n",
      "\n",
      "i = 13\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Input: hide private attributes\n",
      "Prediction: निजी गुणों को छिपाएं\n",
      "Dataset Reference: निजी गुणों को छिपाएं \n",
      "\n",
      "i = 14\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Input: method\n",
      "Prediction: विधि\n",
      "Dataset Reference: विधि \n",
      "\n",
      "i = 15\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Input: property\n",
      "Prediction: गुणधर्म\n",
      "Dataset Reference: गुणधर्म \n",
      "\n",
      "i = 16\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Input: value\n",
      "Prediction: मान\n",
      "Dataset Reference: मान \n",
      "\n",
      "i = 17\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Input: ipython console\n",
      "Prediction: आईपाइथन कन्सोल\n",
      "Dataset Reference: आईपाइथन कन्सोल \n",
      "\n",
      "i = 18\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Input: interactive console for manipulating currently selected accessible\n",
      "Prediction: हेतु अंतर्क्रियात्मक प्रोफाइल लॉक पद्धति सुसंगतता के आज्ञा\n",
      "Dataset Reference: इस समय चुने गए एक्सेसेबेल से काम लेने के लिए अंतर्क्रियात्मक कन्सोल \n",
      "\n",
      "i = 19\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Input: event monitor\n",
      "Prediction: घटना मानिटर\n",
      "Dataset Reference: घटना मानिटर \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing and Analysis\n",
    "candidates = []\n",
    "references = []\n",
    "\n",
    "for i in range(20):\n",
    "\tcur_len = len(X_test[i].split())\n",
    "\tif cur_len <= max_len:\n",
    "\t\tprint(\"i =\", i)\n",
    "\t\tpred_sentence = predict_sentence(X_test[i])\n",
    "\t\t\n",
    "\t\tcandidates.append(pred_sentence.split()[:-1])\n",
    "\t\tprint(\"Input:\", X_test[i])\n",
    "\t\tprint(\"Prediction:\", ' '.join(pred_sentence.split()[:-1]))\n",
    "\t\tprint(\"Dataset Reference:\", ' '.join(y_test[i].split()[1:-1]), \"\\n\")\n",
    "\n",
    "\t\treferences.append([(y_test[i].split()[1:-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035367d",
   "metadata": {},
   "source": [
    "### Finally, computing the BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e852db0-ab7d-4227-895f-d0e691c615d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BLEU score = 0.5204079142754721\n"
     ]
    }
   ],
   "source": [
    "smooth = SmoothingFunction()\n",
    "print(\"Final BLEU score =\", corpus_bleu(references, candidates, smoothing_function=smooth.method7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
